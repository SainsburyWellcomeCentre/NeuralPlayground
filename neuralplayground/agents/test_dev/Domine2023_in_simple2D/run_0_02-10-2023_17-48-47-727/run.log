---> Saving simulation parameters
---> Initializing models
Backend MacOSX is interactive backend. Turning interactive mode on.
---> Training loop
Training step 1: loss = 0.05747459828853607
Training step 2: loss = 0.05675369128584862
Training step 3: loss = 0.057163674384355545
Training step 4: loss = 0.05786101892590523
Training step 5: loss = 0.05777592584490776
Training step 6: loss = 0.05671459063887596
Training step 7: loss = 0.05616319924592972
Training step 8: loss = 0.05817286670207977
Training step 9: loss = 0.05859898775815964
Training step 10: loss = 0.057074300944805145
Training step 11: loss = 0.059366535395383835
Training step 12: loss = 0.056538429111242294
Training step 13: loss = 0.0574747659265995
Training step 14: loss = 0.058955416083335876
Training step 15: loss = 0.05844912678003311
Training step 16: loss = 0.05618777498602867
Training step 17: loss = 0.057931575924158096
Training step 18: loss = 0.05947407707571983
Training step 19: loss = 0.05919237807393074
Training step 20: loss = 0.05582079663872719
Training step 21: loss = 0.06053556129336357
Training step 22: loss = 0.05784456059336662
Training step 23: loss = 0.05644190311431885
Training step 24: loss = 0.05902090668678284
Training step 25: loss = 0.05668891593813896
Training step 26: loss = 0.05693088099360466
Training step 27: loss = 0.06131364777684212
Training step 28: loss = 0.05616411939263344
Training step 29: loss = 0.05988340824842453
Training step 30: loss = 0.05740777775645256
Training step 31: loss = 0.05695880949497223
Training step 32: loss = 0.06169911101460457
Training step 33: loss = 0.059859499335289
Training step 34: loss = 0.05775993689894676
Training step 35: loss = 0.05840311571955681
Training step 36: loss = 0.0579836405813694
Training step 37: loss = 0.05779498815536499
Training step 38: loss = 0.05835229903459549
Training step 39: loss = 0.058808833360672
Training step 40: loss = 0.05736761912703514
Training step 41: loss = 0.05824615806341171
Training step 42: loss = 0.059203315526247025
Training step 43: loss = 0.05660514160990715
Training step 44: loss = 0.058989815413951874
Training step 45: loss = 0.0592421293258667
Training step 46: loss = 0.06022079661488533
Training step 47: loss = 0.057279765605926514
Training step 48: loss = 0.05906372889876366
Training step 49: loss = 0.058453865349292755
Training step 50: loss = 0.05618678778409958
Training step 51: loss = 0.05686214566230774
Training step 52: loss = 0.05839189514517784
Training step 53: loss = 0.05995870381593704
Training step 54: loss = 0.056413404643535614
Training step 55: loss = 0.061875008046627045
Training step 56: loss = 0.058109432458877563
Training step 57: loss = 0.055224496871232986
Training step 58: loss = 0.057966336607933044
Training step 59: loss = 0.05726496875286102
Training step 60: loss = 0.05651327595114708
Training step 61: loss = 0.05684540048241615
Training step 62: loss = 0.0585305280983448
Training step 63: loss = 0.05588407814502716
Training step 64: loss = 0.056134533137083054
Training step 65: loss = 0.05878423899412155
Training step 66: loss = 0.06019381061196327
Training step 67: loss = 0.057269174605607986
Training step 68: loss = 0.05556754022836685
Training step 69: loss = 0.05717654898762703
Training step 70: loss = 0.05853547155857086
Training step 71: loss = 0.058540526777505875
Training step 72: loss = 0.057696517556905746
Training step 73: loss = 0.05888007581233978
