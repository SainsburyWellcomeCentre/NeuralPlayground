{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# UniReps & NeuroAI Hackathon: Aligning Neural Representations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The primary\n",
    " of this hackathon is to explore the **alignment of neural representations**. Specifically, we aim to investigate:\n",
    "\n",
    "- **When, how and why** it is meaningful to align representations\n",
    "- The potential **caveats**, such as:\n",
    "  - Number of recorded cells\n",
    "  - Neural remapping\n",
    "  - Variability across experimental conditions\n",
    "\n",
    "We will adapt methods originally developed for aligning representations in **machine learning** to neuroscience applications, focusing on **grid cell** activity.\n",
    "\n",
    "The hackathon will use the **Neural Playground** platform as our main tool, but feel free to write your own code along the way, and let us know if you don't like something\n",
    "\n",
    "<span style=\"color:red\">**Do we want to say something about what alignment means?**</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## üß† Steps Overview\n",
    "\n",
    "### 1. Data Acquisition\n",
    "\n",
    "We will first introduce these representation found int he entoriehnal coretex We will begin by using Neural Playground to access the **Sargolini dataset**, which includes:\n",
    "\n",
    "- Animal trajectory data\n",
    "- Corresponding grid cell recordings <span style=\"color:red\">**spike data and a way to compute ratemaps**</span>\n",
    "\n",
    "### 2. Agent Training\n",
    "\n",
    "We will build a arena based on the experiemtal imfroamtion and train an artificial agent using the **Stachenfeld successor representation (SR) model**, applying it to the same trajectory as in the experimental data. This will allow us to generate **comparable neural representations**.\n",
    "\n",
    "### 3. Representation Comparison\n",
    "\n",
    "To evaluate and compare biological and artificial representations, we will build **Representational Similarity Matrices (RSMs)**. These will help us quantify and visualize the alignment between the two systems.\n",
    "\n",
    "---\n",
    "\n",
    "Let us know what you'd like to explore further‚Äîwhether it‚Äôs alignment techniques, specific neural metrics, or alternative agent models!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## 1. Data Acquisition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### üß≠ What is a Grid Cell?\n",
    "\n",
    "**Grid cells** are a type of neuron found in the **medial entorhinal cortex** of the brain, first discovered in 2005 by **Hafting et al.** These cells are remarkable for their unique firing patterns: as an animal moves through its environment, a grid cell activates at multiple locations that form a **hexagonal grid-like pattern** across space.\n",
    "\n",
    "This spatially periodic activity makes grid cells essential for **navigation** and **spatial memory**. Unlike place cells, which fire at specific locations, grid cells provide a **universal coordinate system** that can generalize across different environments.\n",
    "\n",
    "Grid cells have become one of the most studied neural representations due to their:\n",
    "\n",
    "- **Structured and regular firing patterns**\n",
    "- **Role in path integration** (estimating position based on self-motion)\n",
    "- **Relevance to models of cognitive mapping and spatial encoding**\n",
    "\n",
    "Understanding grid cells has been crucial in bridging **neuroscience and computational models**, especially in exploring how the brain constructs internal maps of the external world.\n",
    "\n",
    "In this hackathon, we focus on grid cells as a case study to investigate how **neural representations can be aligned** across biological and artificial systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "### Sargolini et al 2006\n",
    "\n",
    "We take the recoding from\n",
    "- *Conjunctive Representation of Position, Direction, and Velocity in Entorhinal Cortex*, Sargolini et al 2006 (https://www.science.org/doi/10.1126/science.1125572)\n",
    "\n",
    "In this experiment the rats freely moved in a 2D square environemt.\n",
    "Bellow we plot the recorded cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:12.299687Z",
     "start_time": "2025-07-23T13:47:11.624413Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from neuralplayground.experiments import Sargolini2006Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:12.757705Z",
     "start_time": "2025-07-23T13:47:12.303089Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sargolini_data = Sargolini2006Data(verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:12.813767Z",
     "start_time": "2025-07-23T13:47:12.807831Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataframe = sargolini_data.show_data(full_dataframe=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:12.855608Z",
     "start_time": "2025-07-23T13:47:12.853296Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "help(sargolini_data.get_tetrode_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:13.090309Z",
     "start_time": "2025-07-23T13:47:12.902009Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(10, 4))\n",
    "x, y, time_array, spikes = sargolini_data.plot_spike_train(recording_index=3, tetrode_id=\"T5C1\", ax=ax)\n",
    "ax.set_xlim([200, 250])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:13.206812Z",
     "start_time": "2025-07-23T13:47:13.096170Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rate_map, x_bin, y_bin = sargolini_data.plot_recording_tetr(recording_index=4, tetrode_id=\"T6C1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:13.310990Z",
     "start_time": "2025-07-23T13:47:13.223632Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "recoring_tetr_list = sargolini_data.plot_recording_tetr(recording_index=[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:14.534714Z",
     "start_time": "2025-07-23T13:47:13.317752Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot every 5 to make the plot lighter\n",
    "x, y, time_steps = sargolini_data.plot_trajectory(recording_index=2, \n",
    "                                                  plot_every=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Exercice:\n",
    "Do the thing bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:15.057269Z",
     "start_time": "2025-07-23T13:47:14.541321Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tetrode_ids = [\"T5C2\", \"T6C1\", \"T6C2\", \"T6C3\", \"T8C2\"]\n",
    "\n",
    "# Arrays to store the output\n",
    "rate_maps = []\n",
    "x_bins = []\n",
    "y_bins = []\n",
    "\n",
    "# Loop over each tetrode ID and extract the data\n",
    "for tet_id in tetrode_ids:\n",
    "    rate_map, x_bin, y_bin = sargolini_data.plot_recording_tetr(\n",
    "        save_path='./trajectory_after_merge_2',\n",
    "        recording_index=4,\n",
    "        tetrode_id=tet_id,\n",
    "        #bin_size=5,\n",
    "    )\n",
    "    print(\"X_mec shape:\", rate_map.shape)\n",
    "    rate_maps.append(rate_map)\n",
    "    x_bins.append(x_bin)\n",
    "    y_bins.append(y_bin)\n",
    "\n",
    "# Stack the flattened rate maps column-wise to form X_mec\n",
    "#X_mec = np.stack(rate_maps, axis=2)  # Shape: (N_locations, N_mec_cells)\n",
    "#print(\"X_mec shape:\", X_mec.shape)  # Should be (N_locations, 5)\n",
    "# Flatten each 2D rate map to a 1D array before stacking\n",
    "rate_maps_flattened = [rate_map.flatten() for rate_map in rate_maps]\n",
    "\n",
    "# Stack the flattened maps column-wise\n",
    "X_mec = np.stack(rate_maps_flattened, axis=1)  # Shape: (2500, 5)\n",
    "\n",
    "print(\"X_mec shape:\", X_mec.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## 2. Agent Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Virtual Arena from Experimental Data\n",
    "\n",
    "The package includes tools for constructing flexible 2D environments with arbitrary geometries defined by \"walls\". These arenas can be easily adapted for different experimental setups.\n",
    "\n",
    "We use metadata from real experiments to generate **virtual arenas** that accurately reflect the spatial structure and constraints of the original behavioral environments. This setup enables direct comparison between neural data and simulated agent activity.\n",
    "\n",
    "This implementation includes simulations in environments modeled after the **Sargolini et al.** experiment, providing a practical way to test the SR model‚Äôs predictions in biologically realistic settings.\n",
    "\n",
    "### üß† Running the Successor Representation (SR) Model\n",
    "\n",
    "This module demonstrates how to train and evaluate an agent using the **Successor Representation (SR)** model, as described in:\n",
    "\n",
    "**Kimberly L. Stachenfeld, Matthew M. Botvinick, & Samuel J. Gershman**\n",
    "[*The hippocampus as a predictive map*, Nature Neuroscience (2017)](https://www.nature.com/articles/nn.4650)\n",
    "\n",
    "\n",
    "The SR model proposes that the hippocampus encodes a predictive map of future states based on current location and transition dynamics.\n",
    "Rather than representing space directly, the model encodes the expected future occupancy of states under a given policy. This allows for flexible, predictive spatial representations that support navigation and learning.\n",
    "\n",
    "![Screenshot%202022-03-25%20at%2016.35.54.png](attachment:Screenshot%202022-03-25%20at%2016.35.54.png)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:15.068681Z",
     "start_time": "2025-07-23T13:47:15.066329Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML, display\n",
    "\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arenas with experimental data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These arenas are pre-configured to follow the dimensions and sampling rate of a real experiment. When initializing these arenas, the recorded data from the corresponding experiment will be automatically loaded using the Experimental Data Class (see [these examples](https://github.com/ClementineDomine/NeuralPlayground/blob/main/examples/experimental_examples/experimental_data_examples.ipynb)). The idea is to create artificial environment with a structure that resembles the experiment, to then compare with experimental recordings. For now, these classes are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:15.204844Z",
     "start_time": "2025-07-23T13:47:15.077334Z"
    }
   },
   "outputs": [],
   "source": [
    "from neuralplayground.arenas import Sargolini2006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:15.630057Z",
     "start_time": "2025-07-23T13:47:15.212158Z"
    }
   },
   "outputs": [],
   "source": [
    "env_name = \"Sargolini2006\"\n",
    "time_step_size = 0.1 #seg\n",
    "agent_step_size = 5\n",
    "\n",
    "env = Sargolini2006(environment_name = env_name,\n",
    "                    time_step_size = time_step_size,\n",
    "                    agent_step_size = agent_step_size,\n",
    "                    use_behavioral_data = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of the methods from the Experiment class are included in these specific arena classes, these methods are ```show_data()```, ```set_animal_data()```, ```plot_recording_tetr()```, ```plot_recorded_trajectory()```. These methods works analogous to the ones available in the [Experiment classes](https://github.com/ClementineDomine/NeuralPlayground/blob/main/examples/experimental_examples/experimental_data_examples.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:15.641745Z",
     "start_time": "2025-07-23T13:47:15.637166Z"
    }
   },
   "outputs": [],
   "source": [
    "recording_list = env.show_data()  # env.data has an object of the experiment class with Sargolini et al data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:16.945378Z",
     "start_time": "2025-07-23T13:47:15.650532Z"
    }
   },
   "outputs": [],
   "source": [
    "env.plot_recorded_trajectory(recording_index=3, plot_every=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can set which recording behavior you want to use by using ```set_animal_data()``` methods as you would do with an experimental class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:16.958096Z",
     "start_time": "2025-07-23T13:47:16.955755Z"
    }
   },
   "outputs": [],
   "source": [
    "env.set_animal_data(recording_index=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§ñ Agent-Environment Interaction\n",
    "\n",
    "The arenas are designed to support interaction with an agent using a similar method to the **OpenAI Gym** interface. The agent receives an observation, updates its representation and returns an action, which the environment uses to update its internal state.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:17.119805Z",
     "start_time": "2025-07-23T13:47:16.967644Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from neuralplayground.agents import Stachenfeld2018\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:17.130230Z",
     "start_time": "2025-07-23T13:47:17.127233Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent_step_size = 5\n",
    "discount = .9\n",
    "threshold = 1e-6\n",
    "lr_td = 1e-2\n",
    "t_episode = 1000\n",
    "n_episode = 100\n",
    "state_density = (1 / agent_step_size)\n",
    "twoDvalue = True\n",
    "\n",
    "agent = Stachenfeld2018(discount=discount, t_episode=t_episode, n_episode=n_episode, threshold=threshold, lr_td=lr_td,\n",
    "               room_width=env.room_width, room_depth=env.room_depth, state_density=state_density, twoD=twoDvalue)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Eigenvector Selection and Projection\n",
    "\n",
    "Here, we select a subset of grid cells and choose **5 eigenvectors** corresponding to the following eigenvalue indices:\n",
    "**1, 10, 15, 20, and 25**.\n",
    "\n",
    "We gather these cells into an array resulting in a matrix of shape: `(N_locations, N_eigvecs)`,\n",
    "\n",
    "---\n",
    "### Additional exercies:\n",
    "For further analysis and comparison, you can modify the set of eigenvalues used and observe how this affects the resulting scores, or which eigenvector you choose.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:19.304845Z",
     "start_time": "2025-07-23T13:47:17.137303Z"
    }
   },
   "outputs": [],
   "source": [
    "sr = agent.update_successor_rep_td_full(n_episode=100, t_episode=100) # One can compute the successor representation using successive additive update\n",
    "agent.plot_rate_map(agent.srmat_full_td, eigen_vectors=[1,10,15,20,25],save_path=None)\n",
    "agent.plot_rate_map(sr, eigen_vectors=[1,10,15,20,25],save_path=None)\n",
    "\n",
    "sr_sum = agent.successor_rep_sum() # One can compute the successor representation matrix using geometric sums for $\\gamma<1$\n",
    "agent.plot_rate_map(agent.srmat_sum, eigen_vectors=[1,10,15,20,25],save_path=None)\n",
    "agent.plot_rate_map(sr_sum, eigen_vectors=[1,10,15,20,25],save_path=None)\n",
    "\n",
    "\n",
    "srmat_ground=agent.successor_rep_solution()\n",
    "agent.plot_rate_map(agent.srmat_ground, eigen_vectors=[1,10,15,20,25],save_path=None)\n",
    "agent.plot_rate_map(srmat_ground, eigen_vectors=10,save_path ='./grids_sr_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:22.541142Z",
     "start_time": "2025-07-23T13:47:19.313890Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_every = 100000\n",
    "total_iters = 0\n",
    "obs, state = env.reset()\n",
    "for i in tqdm(range(100000)):\n",
    "# Observe to choose an action\n",
    "    action = agent.act(obs[:2])  # the action is link to density of state to make sure we always land in a new\n",
    "    agent.update()\n",
    "    obs, state, reward = env.step(action)\n",
    "    obs= obs[:2]\n",
    "    total_iters += 1\n",
    "    if total_iters % plot_every == 0:\n",
    "        agent.plot_rate_map(sr_matrix=agent.srmat,eigen_vectors=[1,10,15,20], save_path='./sr_Sargo.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:22.553758Z",
     "start_time": "2025-07-23T13:47:22.552336Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ax = env.plot_trajectory()\n",
    "# ax.grid()\n",
    "# # ax.legend(fontsize=fontsize, loc=\"upper left\")\n",
    "# ax.set_xlabel(\"width\", fontsize=16)\n",
    "# ax.set_ylabel(\"depth\", fontsize=16)\n",
    "# plt.savefig(\"sargolini.pdf\", bbox_inches=\"tight\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice: Do the thing bellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:22.857742Z",
     "start_time": "2025-07-23T13:47:22.562390Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot every 5 to make the plot lighter\n",
    "eigen_ids = [11,10,15,20,12]\n",
    "\n",
    "# Arrays to store the output\n",
    "rate_maps = []\n",
    "x_bins = []\n",
    "y_bins = []\n",
    "\n",
    "# Loop over each tetrode ID and extract the data\n",
    "for eigen_id in eigen_ids:\n",
    "    rate_map = agent.get_rate_map_matrix(sr_matrix=agent.srmat_ground,eigen_vector=eigen_id)\n",
    "    rate_maps.append(rate_map)\n",
    "    print(\"X_sr shape:\", rate_map.shape)\n",
    "    x_bins.append(x_bin)\n",
    "    y_bins.append(y_bin)\n",
    "\n",
    "rate_maps_flattened = [rate_map.flatten() for rate_map in rate_maps]\n",
    "\n",
    "# Stack the flattened rate maps column-wise to form X_sr\n",
    "X_sr = np.stack(rate_maps_flattened, axis=1)  # Shape: (N_locations, N_mec_cells)\n",
    "\n",
    "print(\"X_sr shape:\", X_sr.shape)  # Should be (N_locations, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:22.867991Z",
     "start_time": "2025-07-23T13:47:22.866826Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Representation Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üß† What Neuroscientists Do in Practice\n",
    "\n",
    "- **Compare statistical properties**, not direct alignments.\n",
    "  - Grid score distributions\n",
    "  - Field spacing\n",
    "  - Orientation distributions\n",
    "  - *Example*: ‚ÄúDo the model‚Äôs firing fields have similar spacing to real MEC data?‚Äù\n",
    "\n",
    "- **Look at population-level decoding or geometry**\n",
    "  - Latent space analysis (e.g., **toroidal topology** ‚Äî *Gardner et al., 2022*)\n",
    "  - Use manifold learning to compare qualitative structure\n",
    "\n",
    "- **Qualitatively compare maps**\n",
    "  - Visual inspection of rate maps and autocorrelograms\n",
    "  - ‚ùå *But not actual 1:1 spatial alignments*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have gathered the data and structured it in the following format:\n",
    "\n",
    "```python\n",
    "# X_mec: (N_locations, N_mec_cells)\n",
    "# X_sr:  (N_locations, N_sr_features)\n",
    "```\n",
    "\n",
    "They are the same size now so it should be perfect to do the analysis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:22.878609Z",
     "start_time": "2025-07-23T13:47:22.877086Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"X_mec shape:\", X_mec.shape)\n",
    "print(\"X_mec shape:\", X_sr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T13:47:23.255329Z",
     "start_time": "2025-07-23T13:47:22.888337Z"
    },
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.linalg import orthogonal_procrustes\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Load your data here ---\n",
    "# X_mec and X_sr must be (N_locations, N_features)\n",
    "# X_mec: real MEC data; X_sr: model representations (e.g., SR eigenvectors)\n",
    "\n",
    "# --- Step 1: Preprocess (center & scale) ---\n",
    "scaler_mec = StandardScaler()\n",
    "X_mec_pre = scaler_mec.fit_transform(X_mec)\n",
    "\n",
    "scaler_sr = StandardScaler()\n",
    "X_sr_pre = scaler_sr.fit_transform(X_sr)\n",
    "\n",
    "# --- Step 2: Procrustes Alignment (FIXED: removed extra scaling) ---\n",
    "R, _ = orthogonal_procrustes(X_sr_pre, X_mec_pre)\n",
    "X_sr_aligned = X_sr_pre @ R\n",
    "\n",
    "# --- Step 3: Quantitative Metrics ---\n",
    "def avg_cosine_sim(X1, X2):\n",
    "    sims = [np.dot(X1[i], X2[i]) /\n",
    "            (np.linalg.norm(X1[i]) * np.linalg.norm(X2[i]))\n",
    "            for i in range(len(X1))]\n",
    "    return np.nanmean(sims)\n",
    "\n",
    "d_aligned = np.linalg.norm(X_mec_pre - X_sr_aligned, 'fro')\n",
    "d_unaligned = np.linalg.norm(X_mec_pre - X_sr_pre, 'fro')\n",
    "cos_sim_aligned = avg_cosine_sim(X_mec_pre, X_sr_aligned)\n",
    "cos_sim_unaligned = avg_cosine_sim(X_mec_pre, X_sr_pre)\n",
    "\n",
    "print(f\"Procrustes Distance (Aligned):   {d_aligned:.4f}\")\n",
    "print(f\"Procrustes Distance (Unaligned): {d_unaligned:.4f}\")\n",
    "print(f\"Avg Cosine Similarity (Aligned):   {cos_sim_aligned:.4f}\")\n",
    "print(f\"Avg Cosine Similarity (Unaligned): {cos_sim_unaligned:.4f}\")\n",
    "\n",
    "# --- Step 4: PCA-Based Visualization ---\n",
    "pca = PCA(n_components=2)\n",
    "pca_all = pca.fit(np.vstack([X_mec_pre, X_sr_pre, X_sr_aligned]))\n",
    "\n",
    "X_mec_2d = pca_all.transform(X_mec_pre)\n",
    "X_sr_2d = pca_all.transform(X_sr_pre)\n",
    "X_sr_aligned_2d = pca_all.transform(X_sr_aligned)\n",
    "\n",
    "spatial_color = np.linspace(0, 1, X_mec.shape[0])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Before alignment\n",
    "axes[0].scatter(*X_mec_2d.T, c=spatial_color, cmap='viridis', s=10, label='MEC')\n",
    "axes[0].scatter(*X_sr_2d.T, c=spatial_color, cmap='plasma', s=10, alpha=0.6, label='SR (Original)')\n",
    "axes[0].set_title('Before Alignment (PCA)')\n",
    "axes[0].legend()\n",
    "\n",
    "# After alignment\n",
    "axes[1].scatter(*X_mec_2d.T, c=spatial_color, cmap='viridis', s=10, label='MEC')\n",
    "axes[1].scatter(*X_sr_aligned_2d.T, c=spatial_color, cmap='plasma', s=10, alpha=0.6, label='SR (Aligned)')\n",
    "axes[1].set_title('After Alignment (PCA)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Step 5: Random Baseline (Shuffle Test, FIXED) ---\n",
    "n_shuffles = 100\n",
    "shuffle_distances = []\n",
    "shuffle_cosines = []\n",
    "\n",
    "for i in range(n_shuffles):\n",
    "    X_sr_shuffled = np.random.permutation(X_sr_pre)\n",
    "    R_rand, _ = orthogonal_procrustes(X_sr_shuffled, X_mec_pre)\n",
    "    X_sr_shuf_aligned = X_sr_shuffled @ R_rand\n",
    "\n",
    "    d_rand = np.linalg.norm(X_mec_pre - X_sr_shuf_aligned, 'fro')\n",
    "    cos_rand = avg_cosine_sim(X_mec_pre, X_sr_shuf_aligned)\n",
    "\n",
    "    shuffle_distances.append(d_rand)\n",
    "    shuffle_cosines.append(cos_rand)\n",
    "\n",
    "# Plot the null distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "axes[0].hist(shuffle_distances, bins=20, color='gray', alpha=0.7)\n",
    "axes[0].axvline(d_aligned, color='red', linestyle='--', label='Actual')\n",
    "axes[0].set_title('Procrustes Distance (Null vs. Observed)')\n",
    "axes[0].legend()\n",
    "\n",
    "axes[1].hist(shuffle_cosines, bins=20, color='gray', alpha=0.7)\n",
    "axes[1].axvline(cos_sim_aligned, color='red', linestyle='--', label='Actual')\n",
    "axes[1].set_title('Cosine Similarity (Null vs. Observed)')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.linalg import orthogonal_procrustes\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Preprocessing (Centering and Scaling) ---\n",
    "# It's good practice to center and scale the data before Procrustes for consistency.\n",
    "# This ensures that differences in mean activity or overall scale don't dominate the alignment.\n",
    "scaler_mec = StandardScaler()\n",
    "X_mec_preprocessed = scaler_mec.fit_transform(X_mec)\n",
    "\n",
    "scaler_sr = StandardScaler()\n",
    "X_sr_preprocessed = scaler_sr.fit_transform(X_sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Perform Procrustes Alignment ---\n",
    "# orthogonal_procrustes(A, B) finds the optimal rotation R and scaling factor `scale`\n",
    "# such that A @ R * scale is as close as possible to B.\n",
    "# Here, we want to align SR to MEC, so SR is 'A' and MEC is 'B'.\n",
    "R, scale = orthogonal_procrustes(X_sr_preprocessed, X_mec_preprocessed)\n",
    "\n",
    "# Apply the transformation to the SR data\n",
    "X_sr_aligned = np.dot(X_sr_preprocessed, R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Calculate Quantitative Metrics ---\n",
    "# Procrustes Distance (Frobenius norm of the difference)\n",
    "procrustes_distance = np.linalg.norm(X_mec_preprocessed - X_sr_aligned, 'fro')\n",
    "print(f\"Procrustes Distance after alignment: {procrustes_distance:.4f}\")\n",
    "\n",
    "# Calculate distance *before* alignment for comparison\n",
    "procrustes_distance_unaligned = np.linalg.norm(X_mec_preprocessed - X_sr_preprocessed, 'fro')\n",
    "print(f\"Procrustes Distance before alignment: {procrustes_distance_unaligned:.4f}\")\n",
    "\n",
    "# Average Cosine Similarity (aligned)\n",
    "cosine_sim_per_location = [np.dot(X_mec_preprocessed[i], X_sr_aligned[i]) /\n",
    "                           (np.linalg.norm(X_mec_preprocessed[i]) * np.linalg.norm(X_sr_aligned[i]))\n",
    "                           for i in range(X_mec_preprocessed.shape[0])]\n",
    "average_cosine_similarity = np.nanmean(cosine_sim_per_location) # Use nanmean to handle potential division by zero if a row is all zeros\n",
    "print(f\"Average Cosine Similarity (aligned): {average_cosine_similarity:.4f}\")\n",
    "\n",
    "# Average Cosine Similarity (unaligned)\n",
    "cosine_sim_per_location_unaligned = [np.dot(X_mec_preprocessed[i], X_sr_preprocessed[i]) /\n",
    "                                     (np.linalg.norm(X_mec_preprocessed[i]) * np.linalg.norm(X_sr_preprocessed[i]))\n",
    "                                     for i in range(X_mec_preprocessed.shape[0])]\n",
    "average_cosine_similarity_unaligned = np.nanmean(cosine_sim_per_location_unaligned)\n",
    "print(f\"Average Cosine Similarity (unaligned): {average_cosine_similarity_unaligned:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Visualization (using the first 2 or 3 dimensions) ---\n",
    "# Even though you have 10 dimensions, you'll still visualize in 2D or 3D for clarity.\n",
    "# You can either use the first 2/3 of the 10 dimensions directly, or run PCA on the 10 dimensions\n",
    "# for visualization purposes if you want to find the directions of maximal variance within those 10.\n",
    "# For simplicity, let's just plot the first two dimensions of the preprocessed data.\n",
    "\n",
    "# Assuming you have `locations` array (N_locations, 2) for coloring\n",
    "# Let's use the x-coordinate of the location for coloring as an example.\n",
    "# Replace with your actual spatial variable for coloring.\n",
    "# For demonstration, let's create a dummy spatial_variable_for_color\n",
    "N_locations = X_mec.shape[0]\n",
    "spatial_variable_for_color = np.linspace(0, 1, N_locations) # Example: just a gradient\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 7))\n",
    "\n",
    "# Before alignment\n",
    "axes[0].scatter(X_mec_preprocessed[:, 0], X_mec_preprocessed[:, 1], c=spatial_variable_for_color, cmap='viridis', s=10, label='MEC')\n",
    "axes[0].scatter(X_sr_preprocessed[:, 0], X_sr_preprocessed[:, 1], c=spatial_variable_for_color, cmap='plasma', s=10, alpha=0.5, label='SR (Original)')\n",
    "axes[0].set_title('Before Procrustes Alignment (First 2 Features)')\n",
    "axes[0].set_xlabel('Feature 1')\n",
    "axes[0].set_ylabel('Feature 2')\n",
    "axes[0].legend()\n",
    "\n",
    "# After alignment\n",
    "axes[1].scatter(X_mec_preprocessed[:, 0], X_mec_preprocessed[:, 1], c=spatial_variable_for_color, cmap='viridis', s=10, label='MEC')\n",
    "axes[1].scatter(X_sr_aligned[:, 0], X_sr_aligned[:, 1], c=spatial_variable_for_color, cmap='plasma', s=10, alpha=0.5, label='SR (Aligned)')\n",
    "axes[1].set_title('After Procrustes Alignment (First 2 Features)')\n",
    "axes[1].set_xlabel('Feature 1')\n",
    "axes[1].set_ylabel('Feature 2')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Step 5: Random Baselines (as discussed previously) ---\n",
    "# This step is still crucial to determine if your alignment is statistically significant.\n",
    "# The code for this remains the same as provided in the detailed plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
