{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b37a69f",
   "metadata": {},
   "source": [
    "# Simulation Manager\n",
    "\n",
    "In this example notebook, we will use the simulation manager tool available in NeuralPlayground. The purpose of this tool is the following:\n",
    "- Run multiple instantiations of model and environments, saved in an organized manner, logging trained agents, error logs, etc…\n",
    "- Keep track of the status of each run.\n",
    "- Access to a default set of simulations that can be easily modified or augmented with new models and environments. \n",
    "- The results from the simulations can be used with the comparison tool, for quick visualization of results.\n",
    "\n",
    "\n",
    "## SingleSim\n",
    "We will start by describing the class that manages single agent-arena pairs, called SingleSim. Objects from this class take the simulation parameters, and it can run the simulation and save the results on the path given by the user, taking care of saving trained agents, simulation parameters, run status, and error logs. \n",
    "\n",
    "First, let's import SR model, a Simple2D arena, and a training loop function that describes the interaction of the agent with the arena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55904f45-6f76-4fc5-bb3f-5527191d4e67",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from neuralplayground.agents import Stachenfeld2018\n",
    "from neuralplayground.arenas import Simple2D\n",
    "from neuralplayground.backend import episode_based_training_loop\n",
    "from neuralplayground.backend import SingleSim"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d76578e9-97c5-4c2f-bd6b-f6fe06a29026",
   "metadata": {},
   "source": [
    "Now, let's define the parameters of each element we imported. The SingleSim objects takes the following arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5afc3716-ee68-43d6-9b27-4e289c2c2993",
   "metadata": {},
   "source": [
    "simulation_id = \"SR_custom_sim\"\n",
    "agent_class = Stachenfeld2018\n",
    "env_class = Simple2D\n",
    "training_loop = episode_based_training_loop\n",
    "\n",
    "# Specific parameters for agents, environments and training loop can be written as dictionaries\n",
    "agent_params = {\"discount\": 0.99,\n",
    "                \"threshold\": 1e-6,\n",
    "                \"lr_td\": 1e-2,\n",
    "                \"state_density\": 1,\n",
    "                \"room_width\": 12,\n",
    "                \"room_depth\": 12,\n",
    "                \"twoD\": True}\n",
    "\n",
    "env_params = {\"arena_x_limits\": [-6, 6],\n",
    "              \"arena_y_limits\": [-6, 6],\n",
    "              \"env_name\": \"env_example\",\n",
    "              \"time_step_size\": 0.2,\n",
    "              \"agent_step_size\": 1}\n",
    "\n",
    "# Short training just for demonstration\n",
    "training_loop_params = {\"t_episode\": 100, \"n_episode\": 10}"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "2fa407f6-4ef6-429f-bac3-507f76f8f67b",
   "metadata": {},
   "source": [
    "We initialize the SingleSim object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0cf14eb",
   "metadata": {},
   "source": [
    "sim = SingleSim(simulation_id = simulation_id,\n",
    "                agent_class = agent_class,\n",
    "                agent_params = agent_params,\n",
    "                env_class = env_class,\n",
    "                env_params = env_params,\n",
    "                training_loop = training_loop,\n",
    "                training_loop_params = training_loop_params)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4987975-eeb7-42a3-8898-17247d96de25",
   "metadata": {},
   "source": [
    "print(sim)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dbe4412-1142-4369-ae21-e3e6321b89d4",
   "metadata": {},
   "source": [
    "sim.run_sim()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "c99e3202-3cbc-4cb5-aeec-87ede70db98a",
   "metadata": {},
   "source": [
    "When running a simulation, the results will be saved in ```results_sim``` in the working directory by default. Every simulation result folder should contain:\n",
    "agent: Trained agent object.\n",
    "arena: Arena object used to train the agent.\n",
    "training_hist.dict: A dictionary with variables returned by the train loop on each iteration.\n",
    "param.dict: Simulation parameters.\n",
    "run.log: Any outputs printed by agents, environments, or training loop during training.\n",
    "error.log: Same as run.log but with errors.\n",
    "state.log: Used with keywords to keep track of the running status of the simulation.\n",
    "\n",
    "So far, when the user runs the simulation calling ```run_sim```, the run will stop if there is an error in the code and will be printed directly on the default output. The logs were made for the simulation manager described later.\n",
    "\n",
    "You can load the results of the specific run using ```load_results``` method, getting the trained agent, environment and training history. These objects have all the methods and attributes from the original simulation at your disposal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98aaca64-039c-4f09-a91d-a5ffe673f52a",
   "metadata": {},
   "source": [
    "trained_agent, env, training_hist = sim.load_results()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c85ffbc-bdfc-426f-8456-1e1080aa24db",
   "metadata": {},
   "source": [
    "sim.show_logs()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4353d9ca-2231-4d51-9993-16d1541c8922",
   "metadata": {},
   "source": [
    "env.plot_trajectory()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "edcc9f55-051a-40a7-860f-06c70f0715a2",
   "metadata": {},
   "source": [
    "Let’s see how the state td error looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d84a2f27-eaa4-49f5-90da-a86d9dbf1837",
   "metadata": {},
   "source": [
    "abs_td_error = [np.mean(np.abs(td)) for td in training_hist[\"state_td_error\"]]\n",
    "plt.plot(abs_td_error)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"abs td error\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "502eef17-ef2a-45f1-b360-ee324bb86b97",
   "metadata": {},
   "source": [
    "The training is a big unstable, we can load the parameters of an existing simulation and run it again with the same or different set of parameters. For example, we can create an empty SingleSim object, load the parameters of the existing one, change the parameters, and run the simulation. Let's try a smaller learning rate and compare the td error throughout training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fccb720e-9093-48c9-81df-d28a0bb15c9a",
   "metadata": {},
   "source": [
    "sim2 = SingleSim()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd376077-0b1e-4eb0-9bc2-d59415482eeb",
   "metadata": {},
   "source": [
    "sim2.load_params(\"results_sim\")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbeb90cb-a8a6-4ae9-b4c9-4bb1bc2f0eae",
   "metadata": {},
   "source": [
    "print(sim2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f5fe485d-f780-4ef6-b725-149f1b08e8c7",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "new_params = sim2.agent_params  # Here we take the agent parameters\n",
    "new_params[\"lr_td\"] = 0.001   # Change the learning rate\n",
    "sim2.agent_params = new_params  # Set the parameters with the new learning rate\n",
    "print(sim2)\n",
    "sim2.run_sim(\"small_lr_sim\")  # Run with all parameters equal except for the learning rate"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f4c03a9-2869-45d1-97e9-917ee6356164",
   "metadata": {},
   "source": [
    "trained_agent, env, training_hist = sim2.load_results(\"small_lr_sim\")\n",
    "abs_td_error2 = [np.mean(np.abs(td)) for td in training_hist[\"state_td_error\"]]\n",
    "plt.plot(abs_td_error, label=\"lr 0.01\")\n",
    "plt.plot(abs_td_error2, label=\"lr 0.001\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"abs td error\")\n",
    "plt.legend()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "84df004d-a7f0-4df9-be9c-3f266e10a711",
   "metadata": {},
   "source": [
    "There are some default simulations that can be found in the [backend code](https://github.com/SainsburyWellcomeCentre/NeuralPlayground/blob/main/neuralplayground/backend/default_simulation.py), where simulation parameters are already configured and initialized as a SingleSim object, for example, Weber2018 running on a squared room "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd9e8e07-9223-49d6-b44b-5e2d65d9c142",
   "metadata": {},
   "source": [
    "from neuralplayground.backend.default_simulation import weber_in_2d"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0d92ca6c-b598-4745-bf6d-ce6dd56f5488",
   "metadata": {},
   "source": [
    "print(weber_in_2d)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "59ed8dcc-5803-41bf-a060-27e428a1de1d",
   "metadata": {},
   "source": [
    "With time, we hope to increase the repository of simulations that can reproduce the results of models from different papers, compare against different experimental findings, and also improve code structure. This allows the user to have access to run models out of the box in a reproducible manner, as well as include their own model to the pipeline to easily run their code (agents, environments, and experiments) against any other class in the repo. At the moment, the configured simulations are just for demonstration, then just running for a few iterations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bce2c79-5512-48e4-912d-44bfe5bc7a2c",
   "metadata": {},
   "source": [
    "## Simulation Manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf26950-4c0a-4ae8-a75a-7aec1e7b775a",
   "metadata": {},
   "source": [
    "Now, let’s introduce the ```SimulationManager``` tool, which takes a list of SingleSim objects and manages each simulation and the state of each run. Let’s take our custom simulation, along with some of the default ones available in the [backend code](aslkdmaslkd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98989a1c-e8fd-4c31-80bd-f58ab92424df",
   "metadata": {},
   "source": [
    "from neuralplayground.backend.default_simulation import stachenfeld_in_2d\n",
    "from neuralplayground.backend import SimulationManager"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "d1effeee-69e6-478e-85a0-7a51f8da1eda",
   "metadata": {},
   "source": [
    "Let's break one of the simulation just to show how the logging system works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fdac1d4-902f-491b-a76a-5a8b50b469d0",
   "metadata": {},
   "source": [
    "aux_params = stachenfeld_in_2d.agent_params\n",
    "aux_params[\"lr_td\"] = \"weird_learning_rate\"  # We are breaking the process on purpose\n",
    "stachenfeld_in_2d.agent_params = aux_params\n",
    "my_sims = [sim, weber_in_2d, stachenfeld_in_2d]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "e26265e8-446c-472b-b676-b317db945353",
   "metadata": {},
   "source": [
    "The simulation manager takes 4 arguments:\n",
    "- ```simulation_list```: List filled with SingleSim objects\n",
    "- ```runs_per_sim```: Integer indicating how many runs per simulation you want to get\n",
    "- ```manager_id```: String that identifies the simulation object, used to save all the results\n",
    "- ```verbose```: If true, print more details about the object\n",
    "- ```existing_simulation```: If you want to re-load the results from an existing simulation, you can give the path to the stored simulation as an argument (it will ignore the rest of the arguments in this case)\n",
    "\n",
    "Then, we can initialize a simulation manager as follows:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "99001a2b-6a86-4a99-9e37-3763381d3b2c",
   "metadata": {},
   "source": [
    "my_manager = SimulationManager(simulation_list = my_sims,\n",
    "                               runs_per_sim = 5,\n",
    "                               manager_id = \"example_simulation\",\n",
    "                               verbose = True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "7287c559-9ada-499c-971c-a30ad109d316",
   "metadata": {},
   "source": [
    "To run every simulation, first, we create the paths where the results will be saved, then we run everything following the parameters of each simulation. One important thing to notice is that in the scenario that there is an error during any of the runs, the simulation manager will log the errors in the corresponding paths and continue with the rest of the runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "58ce7912-024d-4daa-b7e3-134e68a4bd47",
   "metadata": {},
   "source": [
    "my_manager.generate_sim_paths()  # Here is the tree with simulations per model, stored by run id and date"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb7fe460-515c-421d-bf2a-95b1c93c72bf",
   "metadata": {},
   "source": [
    "my_manager.run_all()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0254a2a-4747-4391-ba1b-b93763cffa8c",
   "metadata": {},
   "source": [
    "my_manager.check_run_status()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "07b50662-04dd-47e5-add6-41594a93c123",
   "metadata": {},
   "source": [
    "Note that you can check the status of a large simulation at any point by creating a second SimulationManager object and initializing it using the ```existing_simulation``` argument on an existing running path, then using ```check_run_status```. \n",
    "\n",
    "Now, because we gave invalid arguments to one of our simulation, we can see the error logs saved on each of the runs by using ```show_logs``` method to see what went wrong without having to go to the log file manually. ```show_logs``` works similarly as the method with the same name for the SingleSim objects, except that the user needs to specify the simulation index to see the log. For example, in our case the simulation that went wrong is the third in ```my_sims``` list, therefore we need to give the simulation index = 2 as follows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f060064-cf09-48cf-826d-0f9e175b7f3f",
   "metadata": {},
   "source": [
    "my_manager.show_logs(simulation_index = 2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "53b6df6d-b240-4a91-80f2-7ee1f94833c1",
   "metadata": {},
   "source": [
    "As you can see, the error was generated by us using a learning rate as a string, we can put this back to normal using the same simulation manager. We are going to take the simulation with the problem, change the parameters and rerun just that simulation using the ```rerun_simulation``` method, which will remove runs that failed and replace them with new runs using the new parameters, fixing the issue. Let’s first replace the learning rate with a valid one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "63cdadcc-a7c5-4f8f-a309-38a2add75eb6",
   "metadata": {},
   "source": [
    "aux_params = my_manager.simulation_list[2].agent_params\n",
    "aux_params[\"lr_td\"] = 0.001\n",
    "my_manager.simulation_list[2].agent_params = aux_params"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "fe3033c7-09aa-4e51-8599-a0df589da8aa",
   "metadata": {},
   "source": [
    "Now we can run again with a proper learning rate value, but we don’t one to run all of the other successful simulations, we just want to run the one in the simulation list with index 2, so we use ```rerun_simulation(simulation_index = 2)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4da5cf3-cda1-443b-bf21-c72f8b46493f",
   "metadata": {},
   "source": [
    "my_manager.rerun_simulation(simulation_index=2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "14cb7957-1df6-447b-8cbf-73f87955360e",
   "metadata": {},
   "source": [
    "Finally, we can check the status of each run again and see that they are all finished without errors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "255485d6-64ec-4cec-8d92-2f136122e7ff",
   "metadata": {},
   "source": [
    "my_manager.check_run_status()"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "769a5c9b-b137-42d9-9ecd-ad654cb5d94e",
   "metadata": {},
   "source": [
    "This simulation manager tool is still under development, and if you read this please let us know what you think! This notebook is just an example what can be achieved so far with this package, and we hope to add more features and improve usability for new users, all with the goal of improving the reproducibility of simulations and access to researchers to models, environments and experimental data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006a0e03-4698-4cf3-9657-3b1390c4ba00",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
