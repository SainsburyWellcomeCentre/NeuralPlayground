{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison Example : scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this jupyter notebook we present the implementation of the gridness score as defined by by Sargolini et al 2006 https://pubmed.ncbi.nlm.nih.gov/16675704/. \n",
    "\n",
    "We conduct an autocorrelation analysis of the smoothed spatial rate map. From this analysis, we identified six peaks closest to the central peak and encompassed them within a ring, excluding the central peak. The purpose of this step was to examine the periodicity between these fields . Subsequently, we performed a rotational autocorrelation of this ring and observed the correlations' periodic patterns. To quantify the gridness, we computed a gridness score. This score was determined as the difference between the lowest correlation observed at 60 or 120 degrees of rotation and the highest correlation observed at 30, 90, or 150 degrees of rotation. The results of this analysis are presented as 'gridness measure 1\n",
    "\n",
    "Generraly a score larger than [0.2] clasify as a grid cell.\n",
    "\n",
    "\n",
    " \n",
    "The code was appadted from:\n",
    "\n",
    "https://github.com/rhayman/ephysiopy/blob/12ee57a858161daa44546b75853a3333097ceb8a/ephysiopy/common/fieldcalcs.py#L743\n",
    "\n",
    "We note that other measures have been developped to compute the gridness of a neural representation. We aim to implement a larger variety of score over time.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "source": [
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from neuralplayground.arenas import Wernle2018, MergingRoom, Sargolini2006, Simple2D, BasicSargolini2006,Hafting2008\n",
    "from neuralplayground.agents import Weber2018, Stachenfeld2018, RandomAgent, LevyFlightAgent\n",
    "from neuralplayground.experiments import Wernle2018Data, Hafting2008Data, Sargolini2006Data\n",
    "from neuralplayground.comparison import GridScorer\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "source": [
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimental results \n",
    "\n",
    "We compute the gridness score for various experimental recordings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Sargolini "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_scores function gives as out-put the spacial auto correlogram as well as various measures extracted from a spatial auto correlogram, including the grid score. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "source": [
    "sargolini_data = Sargolini2006Data(verbose=False)\n",
    "env = Sargolini2006(time_step_size=1,\n",
    "                         agent_step_size=None)\n",
    "\n",
    "# Change the recording_index=1 to see differernt celss\n",
    "r_out_im,x_bin, y_bin = env.recording_tetr(recording_index=2)\n",
    "print(x_bin)\n",
    "GridScorer_Sargolini2006 = GridScorer(x_bin)\n",
    "GridScorer_Sargolini2006.plot_grid_score(r_out_im=r_out_im, plot= True)\n",
    "score = GridScorer_Sargolini2006 .get_scores(r_out_im)\n",
    "\n",
    "print('GridScorer_Sargo')\n",
    "print(score)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Hafting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "source": [
    "hafting_data = Hafting2008Data(verbose=False)\n",
    "env = Hafting2008(time_step_size=1,\n",
    "                         agent_step_size=None)\n",
    "r_out_im,x_bin, y_bin = env.recording_tetr(recording_index=6)\n",
    "print(y_bin)\n",
    "GridScorer_Hafting2008 = GridScorer(x_bin )\n",
    "GridScorer_Hafting2008.plot_grid_score(r_out_im=r_out_im, plot= True)\n",
    "score = GridScorer_Hafting2008.get_scores(r_out_im)\n",
    "print(score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot_sac function returns a plot of the auto correlogram."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wernle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "wernle_data =  Wernle2018Data()\n",
    "h, x_bin, y_bin = wernle_data.recording_tetr()\n",
    "r_out_im = h.reshape((x_bin.size, y_bin.size))\n",
    "GridScorer_Wernle = GridScorer(x_bin.size-1)\n",
    "score_Wernle = GridScorer_Wernle.get_scores(r_out_im)\n",
    "GridScorer_Wernle.plot_sac(score_Wernle[0])\n",
    "print('GridScorer_SR')\n",
    "print(score)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "source": [
    "env = Wernle2018(time_step_size=1,\n",
    "                         agent_step_size=None)\n",
    "ax = env.plot_recording_tetr(recording_index=40)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "source": [
    "print('GridScorer_SR')\n",
    "print(score_Wernle[1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents results \n",
    "\n",
    "We compute the gridness score for various Agents output recordings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "source": [
    "# Parameters for a square environment\n",
    "room_width = [-10,10]\n",
    "room_depth = [-10,10]\n",
    "env_name = \"env_example\"\n",
    "time_step_size = 1\n",
    "agent_step_size = 0.5\n",
    "\n",
    "# Init environment\n",
    "envsimple = Simple2D(arena_x_limits = room_width,\n",
    "                     arena_y_limits = room_depth,\n",
    "                     time_step_size = time_step_size,\n",
    "                     agent_step_size = agent_step_size)\n",
    "\n",
    "exc_eta = 2e-4\n",
    "inh_eta = 8e-4\n",
    "model_name = \"model_example\"\n",
    "sigma_exc = np.array([0.05, 0.05])\n",
    "sigma_inh = np.array([0.1, 0.1])\n",
    "Ne = 4900\n",
    "Ni = 1225\n",
    "Nef = 1\n",
    "Nif = 1\n",
    "alpha_i = 1\n",
    "alpha_e = 1\n",
    "we_init = 1.0\n",
    "wi_init = 1.5\n",
    "agent_step_size = 0.1\n",
    "roh = 1\n",
    "agent_Webber = Weber2018(model_name=model_name, exc_eta=exc_eta, inh_eta=inh_eta, sigma_exc=sigma_exc,\n",
    "                  sigma_inh=sigma_inh, Ne=Ne, Ni=Ni, agent_step_size=agent_step_size, ro=roh,\n",
    "                  Nef=Nef, Nif=Nif, room_width=envsimple.room_width, room_depth=envsimple.room_depth,\n",
    "                  alpha_i=alpha_i, alpha_e=alpha_e, we_init=we_init, wi_init=wi_init)\n",
    "\n",
    "plot_every = 1000\n",
    "total_iters = 0\n",
    "n_steps = 4000\n",
    "obs, state = envsimple.reset()\n",
    "for i in tqdm(range(n_steps)):\n",
    "    # Observe to choose an action, the first to numbers in the observation are the xy position of the agent\n",
    "    obs = obs[:2]\n",
    "    action = agent_Webber.act(obs)\n",
    "    # rate = agent.update()\n",
    "    agent_Webber.update()\n",
    "    # Run environment for given action\n",
    "    obs, state, reward = envsimple.step(action, normalize_step=True)\n",
    "    total_iters += 1\n",
    "    if i % plot_every == 0:\n",
    "        agent_Webber.plot_rate_map()\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "source": [
    "print('GridScorer_Webber')\n",
    "\n",
    "r_out_im = agent_Webber.get_rate_map_matrix()\n",
    "GridScorer_Weber2018 = GridScorer(agent_Webber.resolution_width)\n",
    "GridScorer_Weber2018.plot_grid_score(r_out_im=r_out_im, plot= True)\n",
    "score = GridScorer_Weber2018.get_scores(r_out_im)\n",
    "GridScorer_Weber2018.plot_sac(score[0])\n",
    "print(score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stachenfeld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "agent_step_size = 1\n",
    "discount = .9\n",
    "threshold = 1e-6\n",
    "lr_td = 1e-2\n",
    "t_episode = 10000\n",
    "n_episode = 10000\n",
    "state_density = (1 / agent_step_size)\n",
    "twoDvalue = True\n",
    "agent_SR = Stachenfeld2018(discount=discount, t_episode=t_episode, n_episode=n_episode, threshold=threshold, lr_td=lr_td,\n",
    "               room_width=envsimple.room_width, room_depth=envsimple.room_depth, state_density=state_density, twoD=twoDvalue)\n",
    "print('GridScorer_SR')\n",
    "r_out_im=agent_SR.get_rate_map_matrix(eigen_vector=30)\n",
    "\n",
    "GridScorer_Stachenfeld2018 = GridScorer(agent_SR.resolution_width)\n",
    "GridScorer_Stachenfeld2018.plot_grid_score(r_out_im=r_out_im, plot= True)\n",
    "score = GridScorer_Stachenfeld2018.get_scores(r_out_im)\n",
    "\n",
    "print(score)"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Whittington\n",
    "Please refer to [TEM_README.md](examples/agent_examples/TEM_README.md) to run the following part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "source": [
    "import importlib\n",
    "import os\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import neuralplayground.agents.whittington_2020_extras.whittington_2020_analyse as analyse\n",
    "from neuralplayground.plotting import PlotSim"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "source": [
    "simulation_id = \"TEM_custom_plot_sim\"\n",
    "from neuralplayground.saved_models import fetch_model_path\n",
    "save_path = fetch_model_path(\"whittington_2020_in_discritized_objects\")\n",
    "plotting_loop_params = {\"n_episode\": 5000}"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "source": [
    "training_dict = pd.read_pickle(os.path.join(os.getcwd(), save_path, \"params.dict\"))\n",
    "model_weights = pd.read_pickle(os.path.join(save_path, \"agent\"))\n",
    "model_spec = importlib.util.spec_from_file_location(\"model\", save_path + \"whittington_2020_model.py\")\n",
    "model = importlib.util.module_from_spec(model_spec)\n",
    "model_spec.loader.exec_module(model)\n",
    "params = pd.read_pickle(os.path.join(save_path, \"agent_hyper\"))\n",
    "tem = model.Model(params)\n",
    "tem.load_state_dict(model_weights)\n",
    "tem.eval()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "source": [
    "sim = PlotSim(\n",
    "    simulation_id=simulation_id,\n",
    "    agent_class=training_dict[\"agent_class\"],\n",
    "    agent_params=training_dict[\"agent_params\"],\n",
    "    env_class=training_dict[\"env_class\"],\n",
    "    env_params=training_dict[\"env_params\"],\n",
    "    plotting_loop_params=plotting_loop_params,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "source": [
    "trained_agent, trained_env = sim.plot_sim(save_path, n_walks=1000, random_state=False, custom_state=[0.5,0.5])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "source": [
    "with open(os.path.join(save_path, \"NPG_environments.pkl\"), \"rb\") as f:\n",
    "    environments = pickle.load(f)\n",
    "with open(os.path.join(save_path, \"NPG_model_input.pkl\"), \"rb\") as f:\n",
    "    model_input = pickle.load(f)\n",
    "\n",
    "training_dict[\"params\"] = training_dict[\"agent_params\"]\n",
    "del training_dict[\"agent_params\"]\n",
    "agent = training_dict[\"agent_class\"](**training_dict[\"params\"])\n",
    "agent.plot_run(tem, model_input, environments)\n",
    "agent.plot_rate_map(rate_map_type='g');\n",
    "agent.plot_rate_map(rate_map_type='p');\n",
    "rate_map_mat = agent.get_rate_map_matrix(agent.g_rates,1,2)\n",
    "GridScorer = GridScorer(rate_map_mat.shape[0])\n",
    "GridScorer.plot_grid_score(r_out_im = rate_map_mat, plot= True)\n",
    "score = GridScorer.get_scores(rate_map_mat)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
