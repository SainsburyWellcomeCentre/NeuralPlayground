{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import copy as cp\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import importlib\n",
    "\n",
    "import parameters\n",
    "import helper_functions\n",
    "import model as tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TEM' object has no attribute 'train_op_all'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-27bf493cc573>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[0mfetches_all\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches_summary\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches_all_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches_summary_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m fetches_all.extend([model.g, model.p, model.p_g, model.x_gt, model.x_, model.A, model.A_inv, model.accuracy_gt,\n\u001b[1;32m---> 35\u001b[1;33m                     model.train_op_all])\n\u001b[0m\u001b[0;32m     36\u001b[0m fetches_all_.extend([model.g, model.p, model.p_g, model.x_gt, model.x_, model.A, model.A_inv, model.accuracy_gt,\n\u001b[0;32m     37\u001b[0m                      model.temp])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TEM' object has no attribute 'train_op_all'"
     ]
    }
   ],
   "source": [
    "# Create Directories\n",
    "gen_path, train_path, model_path, save_path, script_path = helper_functions.make_directories()\n",
    "\n",
    "# Initialise Parameters\n",
    "pars = parameters.default_params()\n",
    "pars_orig = pars.copy()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "with tf.name_scope('Inputs'):\n",
    "    it_num = tf.placeholder(tf.float32, shape=(), name='it_num')\n",
    "    seq_ind = tf.placeholder(tf.float32, shape=(), name='seq_ind')\n",
    "    rnn = tf.placeholder(tf.float32, shape=(pars['batch_size'], pars['p_size'], pars['p_size']), name='rnn')\n",
    "    rnn_inv = tf.placeholder(tf.float32, shape=(pars['batch_size'], pars['p_size'], pars['p_size']), name='rnn')\n",
    "    x1_two_hot = tf.placeholder(tf.float32, shape=(pars['batch_size'], pars['s_size_comp'], pars['seq_len']),\n",
    "                                name='x1_two_hot')\n",
    "    x1 = tf.placeholder(tf.float32, shape=(pars['batch_size'], pars['s_size'], pars['seq_len']), name='x')\n",
    "    g_ = tf.placeholder(tf.float32, shape=(pars['batch_size'], pars['g_size']), name='g_')\n",
    "    x_ = tf.placeholder(tf.float32, shape=(pars['batch_size'], pars['s_size_comp'] * pars['n_freq']), name='x_')\n",
    "    sh = tf.placeholder(tf.float32, shape=(pars['batch_size'], pars['s_size']), name='shiny')\n",
    "    # need to feed in lists etc\n",
    "    d0 = tf.placeholder(tf.float32, shape=(pars['batch_size'], pars['n_actions'], pars['seq_len']), name='d')\n",
    "    s_visi = tf.placeholder(tf.float32, shape=(pars['batch_size'], pars['seq_len']), name='s_visited')\n",
    "    no_d = tf.placeholder(tf.float32, shape=(pars['batch_size']), name='no_direc_batch')\n",
    "    x_two_hot = tf.unstack(x1_two_hot, axis=2)\n",
    "    x = tf.unstack(x1, axis=2)\n",
    "    d = tf.unstack(d0, axis=2)\n",
    "    s_vis = tf.unstack(s_visi, axis=1)\n",
    "\n",
    "# Initialise Model\n",
    "model = tem.TEM(x, x_, x_two_hot, g_, d, rnn, rnn_inv, it_num, seq_ind, s_vis, sh, no_d, pars)\n",
    "\n",
    "# Initialise Model Variables\n",
    "fetches_all, fetches_summary, fetches_all_, fetches_summary_ = [], [], [], []\n",
    "fetches_all.extend([model.g, model.p, model.p_g, model.x_gt, model.x_, model.A, model.A_inv, model.accuracy_gt,\n",
    "                    model.train_op_all])\n",
    "fetches_all_.extend([model.g, model.p, model.p_g, model.x_gt, model.x_, model.A, model.A_inv, model.accuracy_gt,\n",
    "                     model.temp])\n",
    "fetches_summary.extend([model.lx_p, model.lx_g, model.lx_gt, model.lp, model.lg, model.g, model.p, model.p_g,\n",
    "                        model.x_gt, model.x_, model.A, model.A_inv, model.accuracy_p, model.accuracy_g,\n",
    "                        model.accuracy_gt, model.merged, model.train_op_all])\n",
    "fetches_summary_.extend([model.lx_p, model.lx_g, model.lx_gt, model.lp, model.lg, model.g, model.p, model.p_g,\n",
    "                         model.x_gt, model.x_, model.A, model.A_inv, model.accuracy_p, model.accuracy_g,\n",
    "                         model.accuracy_gt, model.merged, model.temp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-268e489625ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# CREATE SESSION\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msess\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInteractiveSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_to_keep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# saves variables learned during training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtrain_writer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFileWriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# CREATE SESSION\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver(max_to_keep=1)  # saves variables learned during training\n",
    "train_writer = tf.summary.FileWriter(train_path, sess.graph)\n",
    "tf.global_variables_initializer().run()\n",
    "tf.get_default_graph().finalize()\n",
    "\n",
    "# Initialise Variables\n",
    "lx_ps, lx_gs, lx_gts, lps, lgs = [], [], [], [], []\n",
    "accs_p, accs_g, accs_gt = [], [], []\n",
    "check_link_inference = False\n",
    "acc_p, acc_g, acc_gt, seq_index, rn = 0, 0, 0, 0, 0\n",
    "correct_link, positions_link, positions, visited, state_guess = None, None, None, None, None\n",
    "position_all, direc_all = None, None\n",
    "gs_all, ps_all, ps_gen_all, xs_all, gs_timeseries, ps_timeseries, pos_timeseries = \\\n",
    "    [None] * pars['n_envs_save'], [None] * pars['n_envs_save'], [None] * pars['n_envs_save'], \\\n",
    "    [None] * pars['n_envs_save'], [None] * pars['n_envs_save'], [None] * pars['n_envs_save'], \\\n",
    "    [None] * pars['n_envs_save']\n",
    "cell_timeseries, prev_cell_timeseries = None, None\n",
    "accs_x_to, accs_x_from = [None] * pars['n_envs_save'], [None] * pars['n_envs_save']\n",
    "save_needed, save_ticker, summary_needed, summary_ticker, save_model = False, False, False, False, False\n",
    "table, _ = helper_functions.combins_table(pars['s_size_comp'], 2)\n",
    "n_restart = pars['restart_max'] + pars['curriculum_steps']\n",
    "T, F, L, P = None, None, None, None\n",
    "adjs, trans, states_mat, shiny_s, shiny_states = None, None, None, None, None\n",
    "a_rnn, a_rnn_inv = None, None\n",
    "gs, ps, x_s, x_data, start_state, prev_direc = None, None, None, None, None, None\n",
    "n_walk = 100\n",
    "index = 0\n",
    "\n",
    "for i in range(pars['train_iters']):\n",
    "    print('Iter {} of {}'.format(i, n_walk))\n",
    "    # Curriculum of Behaviour Types\n",
    "    pars, shiny_s, rn, n_restart, no_direc_batch = helper_functions.curriculum(pars_orig, pars, n_restart)\n",
    "\n",
    "    # Make Environment\n",
    "    adjs, trans, states_mat, shiny_states = helper_functions.make_environments(pars)\n",
    "\n",
    "    # Create Hebbian Matrices\n",
    "    a_rnn, a_rnn_inv = helper_functions.initialise_hebb(pars)\n",
    "\n",
    "    # Initialise all other Variables\n",
    "    gs, x_s, x_data, start_state, prev_direc, visited = helper_functions.initialise_variables(pars, adjs)\n",
    "\n",
    "    # Collect Walking Data\n",
    "    position_all, direc_all = helper_functions.get_walking_data(start_state, adjs, trans, prev_direc, shiny_states, n_walk * pars['n_walk'], pars)\n",
    "\n",
    "    # Run Model\n",
    "    p, g, x_, x_p, x_g, x_gt = tem.TEM.obs_to_state()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('TEM')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4efa648a72966c10981cb021f031326f0325ec28faaed23b786c4cf5425ed480"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
